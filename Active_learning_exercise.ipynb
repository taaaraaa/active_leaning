{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Active Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download the titanic dataset here: https://drive.google.com/file/d/0Bz9_0VdXvv9bbVhpOEMwUDJ2elU/view?usp=sharing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this exercise, we will simulate active learning. We will keep the small sample of observations for testing and we will test how quality of the model rises when we use active learning to choose labeled observations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# import warnings\n",
    "# warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Data into variable df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv('./titanic/train.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove extra cols\n",
    "df = df.drop(['Name', 'Ticket', 'Cabin'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEST SAMPLE\n",
    "# USE THIS SAMPLE ONLY FOR TESTING\n",
    "test_df = df.sample(n=100, random_state=42)\n",
    "X_test=test_df.drop('Survived', axis=1)\n",
    "y_test=test_df['Survived']\n",
    "# KEEP ONLY THOSE WHO ARE NOT IN THE TEST SET\n",
    "df = df[~df.PassengerId.isin(test_df.PassengerId.tolist())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FIT THE FIRST MODEL ONLY ON THE DATAFRAME START_DF\n",
    "start_df = df.sample(n=100, random_state=42)\n",
    "# DROP OBS FROM START_DF FROM DF\n",
    "df = df[~df.PassengerId.isin(start_df.PassengerId.tolist())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(691, 9)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tasks\n",
    "\n",
    "1. fit the first model only on the **start_df** using **SVM** and evaluate accuracy, precision and recall on test_df\n",
    "2. in each iteration, add 10 observations from **df** to your trainset (choose the observation using active learning approach) \n",
    "    - score all observations in df and take 10 where the model isn't sure what class it is. The probability of surviving will be around 50% \n",
    "3. refit the model and evaluate on **test_df** again.    \n",
    "3. the goal is to converge to the optimal solution as fast as possible by choosing **right** observations in each iteration\n",
    "4. plot the graphs for each eval metric, where on the axis x is iteration number, on y is the metric value for that model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import FeatureUnion\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import MinMaxScaler, OneHotEncoder\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import accuracy_score,precision_score\n",
    "\n",
    "from sklearn.preprocessing import FunctionTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7800\n",
      "Precision: 0.7250\n"
     ]
    }
   ],
   "source": [
    "# Split the data into features (X) and target (y)\n",
    "X = start_df.drop('Survived', axis=1)\n",
    "y = start_df['Survived']\n",
    "\n",
    "\n",
    "\n",
    "# Define the transformation we want as a function\n",
    "numeric_transform = Pipeline([('impute_mean', SimpleImputer(strategy='mean')),                            \n",
    "                              ('scaling', MinMaxScaler())])\n",
    "\n",
    "categorical_transform = Pipeline([('impute_mode', SimpleImputer(strategy='most_frequent')), \n",
    "                                  ('one-hot-encode', OneHotEncoder(sparse=False))])\n",
    "\n",
    "\n",
    "# (name, transformer, list of column names)\n",
    "preprocessing_tips = ColumnTransformer([('numeric', numeric_transform, ['Pclass', 'Age','SibSp', 'Parch','Fare']), \n",
    "                                        ('categorical', categorical_transform, \n",
    "                                         ['Sex', 'Embarked'])])\n",
    "\n",
    "#classifier\n",
    "classifier = SVC(probability = True)\n",
    "\n",
    "\n",
    "pipeline = Pipeline(steps=[('preprocessing', preprocessing_tips),                           \n",
    "                           ('classifier', classifier)])\n",
    "\n",
    "pipeline.fit(X,y)\n",
    "y_pred = pipeline.predict(X_test)\n",
    "y_pred_proba = pipeline.predict_proba(X_test) \n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision=precision_score(y_test,y_pred)\n",
    "\n",
    "\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "\n",
    "\n",
    "result={}\n",
    "\n",
    "result['Before_Active_Learning']=list ((round(accuracy,3),round(precision,3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df1=df.drop(['Survived'], axis=1)\n",
    "# df1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    " def accuracy_precision(start_df):\n",
    "    X = start_df.drop('Survived', axis=1)\n",
    "    y = start_df['Survived']\n",
    "    \n",
    "    numeric_transform = Pipeline([('impute_mean', SimpleImputer(strategy='mean')),                            \n",
    "                                  ('scaling', MinMaxScaler())])\n",
    "\n",
    "    categorical_transform = Pipeline([('impute_mode', SimpleImputer(strategy='most_frequent')), \n",
    "                                      ('one-hot-encode', OneHotEncoder(sparse=False))])\n",
    "    preprocessing_tips = ColumnTransformer([('numeric', numeric_transform, ['Pclass', 'Age','SibSp', 'Parch','Fare']), \n",
    "                                            ('categorical', categorical_transform, \n",
    "                                             ['Sex', 'Embarked'])])\n",
    "\n",
    "    classifier = SVC(probability = True)\n",
    "    pipeline = Pipeline(steps=[('preprocessing', preprocessing_tips),                           \n",
    "                               ('classifier', classifier)])\n",
    "    pipeline.fit(X,y)\n",
    "    y_pred = pipeline.predict(X_test)\n",
    "    y_pred_proba = pipeline.predict_proba(X_test) \n",
    "\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision=precision_score(y_test,y_pred)\n",
    "\n",
    "    #return accuracy and precision\n",
    "    return list ((round(accuracy,3),round(precision,3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a = pipeline.predict_proba(df1)[:,1]\n",
    "# b = df1.iloc[np.argwhere((a >=0.3) & (a<=0.7) ) [:10, 0] ]\n",
    "# df1 = df1[~df1.PassengerId.isin(b.PassengerId.tolist())]\n",
    "# start_df= pd.concat([start_df, b])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df1=df.drop(['Survived'], axis=1)\n",
    "df1=df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.79, 0.744]\n",
      "------------\n",
      "[0.8, 0.763]\n",
      "------------\n",
      "[0.8, 0.763]\n",
      "------------\n",
      "[0.8, 0.763]\n",
      "------------\n",
      "[0.81, 0.784]\n",
      "------------\n",
      "[0.81, 0.784]\n",
      "------------\n",
      "[0.81, 0.784]\n",
      "------------\n"
     ]
    }
   ],
   "source": [
    "for i in range(20):\n",
    "    #print(i)\n",
    "    #Running model on df1 to get the prob\n",
    "    a = pipeline.predict_proba(df1)[:,1]\n",
    "    #creating a 10 row table out of the prob that are in middle\n",
    "    b = df1.iloc[np.argwhere((a >=0.3) & (a<=0.7) ) [:10, 0] ]\n",
    "    \n",
    "    #Iterate while there are rows with uncertain probability\n",
    "    if b.shape[0]==0:\n",
    "        break\n",
    "    \n",
    "    #Removing the values from df1 for next itteration\n",
    "    df1 = df1[~df1.PassengerId.isin(b.PassengerId.tolist())]    \n",
    "    \n",
    "    #adding values to start_df\n",
    "    start_df= pd.concat([start_df, b]).copy()\n",
    "\n",
    "    print(accuracy_precision(start_df))\n",
    "\n",
    "    result[f'Itter_{i+1}']=accuracy_precision(start_df)\n",
    "\n",
    "    print('------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Itter_5 [0.81, 0.784] \n",
      "\n",
      "{'Before_Active_Learning': [0.78, 0.725], 'Itter_1': [0.79, 0.744], 'Itter_2': [0.8, 0.763], 'Itter_3': [0.8, 0.763], 'Itter_4': [0.8, 0.763], 'Itter_5': [0.81, 0.784], 'Itter_6': [0.81, 0.784], 'Itter_7': [0.81, 0.784]}\n"
     ]
    }
   ],
   "source": [
    "aaa=max(result, key=lambda x: sum(result[x]))\n",
    "\n",
    "# bbb=sum(result[max(result, key=lambda x: sum(result[x]))])\n",
    "bbb=result[str(aaa)]\n",
    "\n",
    "print(aaa,bbb,'\\n')\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
